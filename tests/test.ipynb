{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating trajectories version 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from imitation.policies.serialize import load_policy\n",
    "from imitation.util.util import make_vec_env\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from imitation.data import rollout\n",
    "from imitation.algorithms.adversarial.gail import GAIL\n",
    "from imitation.rewards.reward_nets import BasicRewardNet\n",
    "from imitation.util.networks import RunningNorm\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from imitation.data.types import Trajectory,DictObs,TrajectoryWithRew,Tuple\n",
    "import h5py\n",
    "from GailNavigationNetwork.model import NaviNet\n",
    "from GailNavigationNetwork.utilities import preprocess\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_demos(file_path,DEVICE=\"cuda\"):\n",
    "    '''\n",
    "    Creates a gymnasium transition from the given file path\n",
    "    of hdf5 file of known structure\n",
    "\n",
    "    Args:\n",
    "    file_path: str  \n",
    "    Path to the hdf5 file   \n",
    "\n",
    "    Returns:\n",
    "    rollouts: gymnasium.Transition\n",
    "\n",
    "    '''    \n",
    "    read_file= h5py.File(file_path, \"r\")\n",
    "    model= NaviNet().to(DEVICE)\n",
    "    model.eval()\n",
    "    len= read_file['kris_dynamics']['odom_data']['target_vector'].shape[0]\n",
    "    rgbs=[]\n",
    "    depths=[]\n",
    "    targets=[]  \n",
    "    acts=[]\n",
    "    ob=[]\n",
    "    for i in range(len):\n",
    "        target=read_file['kris_dynamics']['odom_data']['target_vector'][i]\n",
    "        rgb=read_file['images']['rgb_data'][i]\n",
    "        depth=read_file['images']['depth_data'][i]\n",
    "        act=read_file['kris_dynamics']['odom_data']['odom_data_wheel'][i]\n",
    "        # print(f\"depth shape in rollout {depth.shape}\")\n",
    "        rgb=preprocess(rgb)\n",
    "        depth=preprocess(depth)\n",
    "        # rgb,depth=preprocess(rgb,depth)\n",
    "        (rgb, depth) = (rgb.to(DEVICE), depth.to(DEVICE))\n",
    "        rgb_features, depth_features = model(rgb,depth)\n",
    "        rgb_features=rgb_features.detach().cpu().numpy()\n",
    "        depth_features=depth_features.detach().cpu().numpy()\n",
    "        rgbs.append(rgb_features)\n",
    "        depths.append(depth_features)\n",
    "        targets.append(target) \n",
    "        acts.append(act)\n",
    "        \n",
    "\n",
    "    acts=np.array(acts[:-1])\n",
    "    dones=[False for i in range(len)]\n",
    "    dones[-1]=True\n",
    "    infos= [{} for i in range(len-1)]\n",
    "    rgbs=np.array(rgbs).reshape(25, 1, 1280, 8, 10)\n",
    "    depths=np.array(depths).reshape(25, 1,  238, 318)\n",
    "    targets=np.array(targets).reshape(25, 1, 7)\n",
    "\n",
    "\n",
    "\n",
    "# Combine into one tuple\n",
    "\n",
    "    # obs_dict=tuple((targets,\n",
    "    #         rgbs,\n",
    "    #          depths))\n",
    "    # for i in range(len-1):\n",
    "    #     obs_dict[0][i]=np.array(obs_dict[0][i])\n",
    "    #     obs_dict[1][i]=np.array(obs_dict[1][i])\n",
    "    #     obs_dict[2][i]=np.array(obs_dict[2][i])\n",
    "    \n",
    "    # print(f\"obs_dict shape {obs_tuple[0].shape} {obs_tuple[1].shape} {obs_tuple[2].shape}\")\n",
    "    ob=np.array(ob)\n",
    "\n",
    "    traj = Trajectory(obs=ob, acts=acts,infos=infos,terminal=dones)\n",
    "\n",
    "\n",
    "    return rollout.flatten_trajectories([traj])\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "file_path=\"/home/foxy_user/foxy_ws/src/gail_navigation/GailNavigationNetwork/data/traj2.hdf5\"\n",
    "demonstrations,rollout=create_demos(file_path)\n",
    "print(f\"rollout {rollout[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating trajectories version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device is cuda of name NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from typing import (\n",
    "    Any,    \n",
    "    Dict,\n",
    "    Hashable, \n",
    "    List,\n",
    "    Mapping,    \n",
    "    Sequence,    \n",
    "    Union,\n",
    ")\n",
    "\n",
    "from GailNavigationNetwork.model import NaviNet\n",
    "from GailNavigationNetwork.utilities import preprocess\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.common.base_class import BaseAlgorithm\n",
    "from stable_baselines3.common.policies import BasePolicy\n",
    "from stable_baselines3.common.utils import check_for_correct_spaces\n",
    "from stable_baselines3.common.vec_env import VecEnv\n",
    "from imitation.data import types\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TrajectoryAccumulator:\n",
    "    \"\"\"Accumulates trajectories step-by-step.\n",
    "\n",
    "    Useful for collecting completed trajectories while ignoring partially-completed\n",
    "    trajectories (e.g. when rolling out a VecEnv to collect a set number of\n",
    "    transitions). Each in-progress trajectory is identified by a 'key', which enables\n",
    "    several independent trajectories to be collected at once. They key can also be left\n",
    "    at its default value of `None` if you only wish to collect one trajectory.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialise the trajectory accumulator.\"\"\"\n",
    "        self.partial_trajectories = collections.defaultdict(list)\n",
    "\n",
    "    def add_step(\n",
    "        self,\n",
    "        step_dict: Mapping[str, Union[types.Observation, Mapping[str, Any]]],\n",
    "        key: Hashable = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Add a single step to the partial trajectory identified by `key`.\n",
    "\n",
    "        Generally a single step could correspond to, e.g., one environment managed\n",
    "        by a VecEnv.\n",
    "\n",
    "        Args:\n",
    "            step_dict: dictionary containing information for the current step. Its\n",
    "                keys could include any (or all) attributes of a `TrajectoryWithRew`\n",
    "                (e.g. \"obs\", \"acts\", etc.).\n",
    "            key: key to uniquely identify the trajectory to append to, if working\n",
    "                with multiple partial trajectories.\n",
    "        \"\"\"\n",
    "        print(f\"added partial traj\")\n",
    "        self.partial_trajectories[key].append(step_dict)\n",
    "\n",
    "    def finish_trajectory(\n",
    "        self,\n",
    "        key: Hashable,\n",
    "        terminal: bool,\n",
    "    ) -> types.TrajectoryWithRew:\n",
    "        \"\"\"Complete the trajectory labelled with `key`.\n",
    "\n",
    "        Args:\n",
    "            key: key uniquely identifying which in-progress trajectory to remove.\n",
    "            terminal: trajectory has naturally finished (i.e. includes terminal state).\n",
    "\n",
    "        Returns:\n",
    "            traj: list of completed trajectories popped from\n",
    "                `self.partial_trajectories`.\n",
    "        \"\"\"\n",
    "        part_dicts = self.partial_trajectories[key]\n",
    "        del self.partial_trajectories[key]\n",
    "        out_dict_unstacked = collections.defaultdict(list)\n",
    "        for part_dict in part_dicts:\n",
    "            for k, array in part_dict.items():\n",
    "                out_dict_unstacked[k].append(array)\n",
    "\n",
    "        out_dict_stacked = {\n",
    "            k: types.stack_maybe_dictobs(arr_list)\n",
    "            for k, arr_list in out_dict_unstacked.items()\n",
    "        }\n",
    "        traj = types.TrajectoryWithRew(**out_dict_stacked, terminal=terminal)\n",
    "        assert traj.rews.shape[0] == traj.acts.shape[0] == len(traj.obs) - 1\n",
    "        return traj\n",
    "\n",
    "    def add_steps_and_auto_finish(\n",
    "        self,\n",
    "        acts: np.ndarray,\n",
    "        obs: Union[types.Observation, Dict[str, np.ndarray]],\n",
    "        rews: np.ndarray,\n",
    "        dones: np.ndarray,\n",
    "        infos: List[dict],\n",
    "    ) -> List[types.TrajectoryWithRew]:\n",
    "        \"\"\"Calls `add_step` repeatedly using acts and the returns from `venv.step`.\n",
    "\n",
    "        Also automatically calls `finish_trajectory()` for each `done == True`.\n",
    "        Before calling this method, each environment index key needs to be\n",
    "        initialized with the initial observation (usually from `venv.reset()`).\n",
    "\n",
    "        See the body of `util.rollout.generate_trajectory` for an example.\n",
    "\n",
    "        Args:\n",
    "            acts: Actions passed into `VecEnv.step()`.\n",
    "            obs: Return value from `VecEnv.step(acts)`.\n",
    "            rews: Return value from `VecEnv.step(acts)`.\n",
    "            dones: Return value from `VecEnv.step(acts)`.\n",
    "            infos: Return value from `VecEnv.step(acts)`.\n",
    "\n",
    "        Returns:\n",
    "            A list of completed trajectories. There should be one trajectory for\n",
    "            each `True` in the `dones` argument.\n",
    "        \"\"\"\n",
    "        trajs: List[types.TrajectoryWithRew] = []\n",
    "        wrapped_obs = types.maybe_wrap_in_dictobs(obs)\n",
    "\n",
    "        # iterate through environments\n",
    "        for env_idx in range(len(wrapped_obs)):\n",
    "            assert env_idx in self.partial_trajectories\n",
    "            assert list(self.partial_trajectories[env_idx][0].keys()) == [\"obs\"], (\n",
    "                \"Need to first initialize partial trajectory using \"\n",
    "                \"self._traj_accum.add_step({'obs': ob}, key=env_idx)\"\n",
    "            )\n",
    "        print(f'Debug : {acts} ')\n",
    "        print(f'Debug : {len(wrapped_obs)} ')\n",
    "\n",
    "        print(f'Debug : {rews} ')\n",
    "        print(f'Debug :  {dones}')\n",
    "        print(f'Debug :  {len(infos)}')\n",
    "\n",
    "\n",
    "\n",
    "        # iterate through steps\n",
    "        zip_iter = enumerate(zip(acts, wrapped_obs, rews, dones, infos))\n",
    "        for env_idx, (act, ob, rew, done, info) in zip_iter:\n",
    "            if done:\n",
    "                # When dones[i] from VecEnv.step() is True, obs[i] is the first\n",
    "                # observation following reset() of the ith VecEnv, and\n",
    "                # infos[i][\"terminal_observation\"] is the actual final observation.\n",
    "                real_ob = types.maybe_wrap_in_dictobs(info[\"terminal_observation\"])\n",
    "            else:\n",
    "                real_ob = ob\n",
    "\n",
    "            self.add_step(\n",
    "                dict(\n",
    "                    acts=act,\n",
    "                    rews=rew,\n",
    "                    # this is not the obs corresponding to `act`, but rather the obs\n",
    "                    # *after* `act` (see above)\n",
    "                    obs=real_ob,\n",
    "                    infos=info,\n",
    "                ),\n",
    "                env_idx,\n",
    "            )\n",
    "            if done:\n",
    "                # finish env_idx-th trajectory\n",
    "                new_traj = self.finish_trajectory(env_idx, terminal=True)\n",
    "                trajs.append(new_traj)\n",
    "                # When done[i] from VecEnv.step() is True, obs[i] is the first\n",
    "                # observation following reset() of the ith VecEnv.\n",
    "                self.add_step(dict(obs=ob), env_idx)\n",
    "        return trajs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TrajFromFile:\n",
    "\n",
    "    def __init__(self,file_path,DEVICE=\"cuda\"):\n",
    "        self.file_path=file_path\n",
    "        self.read_file= h5py.File(file_path, \"r\")\n",
    "        self.model= NaviNet().to(DEVICE)\n",
    "        self.model.eval()\n",
    "        self.len= self.read_file['kris_dynamics']['odom_data']['target_vector'].shape[0]\n",
    "        self.rgbs=[]\n",
    "        self.depths=[]\n",
    "        self.targets=[]  \n",
    "        self.acts=[]\n",
    "        self.ob=[]\n",
    "        self.DEVICE=DEVICE\n",
    "        ## Here get the dataset propetiees so features like sample_until can be used\n",
    "\n",
    "    def get_demo(self,idx):\n",
    "        ''''\n",
    "        Return the demonstration at the given index\n",
    "        '''\n",
    "        target=self.read_file['kris_dynamics']['odom_data']['target_vector'][idx]\n",
    "        rgb=self.read_file['images']['rgb_data'][idx]\n",
    "        depth=self.read_file['images']['depth_data'][idx]\n",
    "        act=self.read_file['kris_dynamics']['odom_data']['odom_data_wheel'][idx]\n",
    "        rgb=preprocess(rgb)\n",
    "        depth=preprocess(depth)\n",
    "        (rgb, depth) = (rgb.to(self.DEVICE), depth.to(self.DEVICE))\n",
    "        rgb_features, depth_features = self.model(rgb,depth)\n",
    "        rgb_features=rgb_features.detach().cpu().numpy()\n",
    "        depth_features=depth_features.detach().cpu().numpy()\n",
    "\n",
    "        obs={\n",
    "            'target_vector': np.array([target], dtype=np.float32),\n",
    "            'rgb_features': np.array([rgb_features], dtype=np.float32),\n",
    "            'depth_features': np.array([depth_features], dtype=np.float32)\n",
    "        }\n",
    "\n",
    "        rew=0\n",
    "        done=[False if self.len-1!=idx else True]\n",
    "        info={}\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        return act,obs,rew,done,info\n",
    "    \n",
    "    def generate_trajectories(\n",
    "        self,            \n",
    "        venv: VecEnv,\n",
    "        sample_until,     \n",
    "    ) -> Sequence[types.TrajectoryWithRew]:\n",
    "        \"\"\"Generate trajectory dictionaries from a policy and an environment.\n",
    "\n",
    "        Args:\n",
    "            policy: Can be any of the following:\n",
    "                1) A stable_baselines3 policy or algorithm trained on the gym environment.\n",
    "                2) A Callable that takes an ndarray of observations and returns an ndarray\n",
    "                of corresponding actions.\n",
    "                3) None, in which case actions will be sampled randomly.\n",
    "            venv: The vectorized environments to interact with.\n",
    "            sample_until: An integer defining lenth of recored trajectory\n",
    "            deterministic_policy: If True, asks policy to deterministically return\n",
    "                action. Note the trajectories might still be non-deterministic if the\n",
    "                environment has non-determinism!\n",
    "            rng: used for shuffling trajectories.\n",
    "\n",
    "        Returns:\n",
    "            Sequence of trajectories, satisfying `sample_until`. Additional trajectories\n",
    "            may be collected to avoid biasing process towards short episodes; the user\n",
    "            should truncate if required.\n",
    "        \"\"\"\n",
    "        # Replace this with the function to get the saved trjacotries\n",
    "        # But output in the same format as the policy_to_callable\n",
    "        # get_actions = policy_to_callable(policy, venv, deterministic_policy)\n",
    "\n",
    "        # Collect rollout tuples.\n",
    "        trajectories = []\n",
    "        # accumulator for incomplete trajectories\n",
    "        trajectories_accum = TrajectoryAccumulator()\n",
    "\n",
    "        # Initialize the trajectories with the first observation.\n",
    "        _, obs , _ , _ , _= self.get_demo(0)\n",
    "            # obs, rews, dones, infos = venv.step(acts)    \n",
    "\n",
    "        wrapped_obs = types.maybe_wrap_in_dictobs(obs)\n",
    "\n",
    "        # we use dictobs to iterate over the envs in a vecenv\n",
    "        for ob in (wrapped_obs):\n",
    "            # Seed with first obs only. Inside loop, we'll only add second obs from\n",
    "            # each (s,a,r,s') tuple, under the same \"obs\" key again. That way we still\n",
    "            # get all observations, but they're not duplicated into \"next obs\" and\n",
    "            # \"previous obs\" (this matters for, e.g., Atari, where observations are\n",
    "            # really big).\n",
    "            ## Here I replacec the env_idx with 1 as there is only a single idx \n",
    "            trajectories_accum.add_step(dict(obs=ob),0)\n",
    "            print(\"Added the first observation\")\n",
    "\n",
    "        # Now, we sample until `sample_until(trajectories)` is true.\n",
    "        # If we just stopped then this would introduce a bias towards shorter episodes,\n",
    "        # since longer episodes are more likely to still be active, i.e. in the process\n",
    "        # of being sampled from. To avoid this, we continue sampling until all epsiodes\n",
    "        # are complete.\n",
    "        #\n",
    "     \n",
    "        dones = np.zeros(venv.num_envs, dtype=bool)\n",
    "\n",
    "        \n",
    "        for idx in range(sample_until-1):\n",
    "            acts, obs , rews , dones , infos= self.get_demo(idx+1)\n",
    "            # obs, rews, dones, infos = venv.step(acts)    \n",
    "            wrapped_obs = types.maybe_wrap_in_dictobs(obs)\n",
    "\n",
    "            # If an environment is inactive, i.e. the episode completed for that\n",
    "            # environment after `sample_until(trajectories)` was true, then we do\n",
    "            # *not* want to add any subsequent trajectories from it. We avoid this\n",
    "            # by just making it never done.\n",
    "            # dones &= active\n",
    "\n",
    "            new_trajs = trajectories_accum.add_steps_and_auto_finish(\n",
    "                acts,\n",
    "                wrapped_obs,\n",
    "                rews,\n",
    "                dones,\n",
    "                infos,\n",
    "            )\n",
    "            trajectories.extend(new_trajs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Note that we just drop partial trajectories. This is not ideal for some\n",
    "        # algos; e.g. BC can probably benefit from partial trajectories, too.\n",
    "\n",
    "        # Each trajectory is sampled i.i.d.; however, shorter episodes are added to\n",
    "        # `trajectories` sooner. Shuffle to avoid bias in order. This is important\n",
    "        # when callees end up truncating the number of trajectories or transitions.\n",
    "        # It is also cheap, since we're just shuffling pointers.\n",
    "        # rng.shuffle(trajectories)  # type: ignore[arg-type]\n",
    "\n",
    "        # Sanity checks.\n",
    "        for trajectory in trajectories:\n",
    "            n_steps = len(trajectory.acts)\n",
    "            # extra 1 for the end\n",
    "            if isinstance(venv.observation_space, spaces.Dict):\n",
    "                exp_obs = {}\n",
    "                for k, v in venv.observation_space.items():\n",
    "                    assert v.shape is not None\n",
    "                    exp_obs[k] = (n_steps + 1,) + v.shape\n",
    "            else:\n",
    "                obs_space_shape = venv.observation_space.shape\n",
    "                assert obs_space_shape is not None\n",
    "                exp_obs = (n_steps + 1,) + obs_space_shape  # type: ignore[assignment]\n",
    "            real_obs = trajectory.obs.shape\n",
    "            assert real_obs == exp_obs, f\"expected shape {exp_obs}, got {real_obs}\"\n",
    "            assert venv.action_space.shape is not None\n",
    "            exp_act = (n_steps,) + venv.action_space.shape\n",
    "            real_act = trajectory.acts.shape\n",
    "            assert real_act == exp_act, f\"expected shape {exp_act}, got {real_act}\"\n",
    "            exp_rew = (n_steps,)\n",
    "            real_rew = trajectory.rews.shape\n",
    "            assert real_rew == exp_rew, f\"expected shape {exp_rew}, got {real_rew}\"\n",
    "\n",
    "        return trajectories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from imitation.util.util import make_vec_env\n",
    "import kris_envs\n",
    "import rclpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foxy_user/venvs/thesis_venv/lib/python3.8/site-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment kris_envs/KrisEnv-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.deprecation(\n",
      "[INFO] [1712048762.551807788] [kris_env_node]: Waiting for camera feed\n",
      "[INFO] [1712048762.553315176] [kris_env_node]: Waiting for camera feed\n",
      "[WARN] [1712048762.671679497] [rcl.logging_rosout]: Publisher already registered for provided node name. If this is due to multiple nodes with the same name then all logs for that logger name will go out over the existing publisher. As soon as any node with that name is destructed it will unregister the publisher, preventing any further logs for that name from being published on the rosout topic.\n",
      "[WARN] [1712048762.675639117] [rcl.logging_rosout]: Publisher already registered for provided node name. If this is due to multiple nodes with the same name then all logs for that logger name will go out over the existing publisher. As soon as any node with that name is destructed it will unregister the publisher, preventing any further logs for that name from being published on the rosout topic.\n",
      "[INFO] [1712048762.678847335] [kris_env_node]: Waiting for camera feed\n",
      "[INFO] [1712048762.679619115] [kris_env_node]: Waiting for camera feed\n",
      "[INFO] [1712048762.680134852] [kris_env_node]: Waiting for camera feed\n",
      "[INFO] [1712048762.708502389] [kris_env_node]: Waiting for camera feed\n",
      "[INFO] [1712048762.741926300] [kris_env_node]: Waiting for camera feed\n",
      "[INFO] [1712048762.756365819] [kris_env_node]: Waiting for camera feed\n",
      "[INFO] [1712048762.758475730] [kris_env_node]: Waiting for camera feed\n",
      "[INFO] [1712048762.857146324] [gazebo_connection_node]: /gazebo/reset_simulation service call successful\n",
      "[INFO] [1712048762.933332854] [kris_env_node]: target vector shape (1, 7)\n",
      "/home/foxy_user/venvs/thesis_venv/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "rclpy.init()\n",
    "env = make_vec_env(\n",
    "        \"kris_envs/KrisEnv-v0\",\n",
    "        rng=np.random.default_rng(),\n",
    "        n_envs=1,\n",
    "        post_wrappers=[lambda env, _: RolloutInfoWrapper(env)],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traj object created with lenth 25\n",
      "added partial traj\n",
      "Added the first observation\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m trajectory\u001b[38;5;241m=\u001b[39mTrajFromFile(file_path)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraj object created with lenth\u001b[39m\u001b[38;5;124m\"\u001b[39m,trajectory\u001b[38;5;241m.\u001b[39mlen)\n\u001b[0;32m----> 4\u001b[0m trajs\u001b[38;5;241m=\u001b[39m\u001b[43mtrajectory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlen\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 277\u001b[0m, in \u001b[0;36mTrajFromFile.generate_trajectories\u001b[0;34m(self, venv, sample_until)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# for idx in range(sample_until-1):\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m#     acts, obs , rews , dones , infos= self.get_demo(idx+1)\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m#     # obs, rews, dones, infos = venv.step(acts)    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m#     trajectories.extend(new_trajs)\u001b[39;00m\n\u001b[1;32m    276\u001b[0m ranges\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,sample_until)\n\u001b[0;32m--> 277\u001b[0m acts, obs , rews , dones , infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_demo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mranges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# obs, rews, dones, infos = venv.step(acts)    \u001b[39;00m\n\u001b[1;32m    279\u001b[0m wrapped_obs \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mmaybe_wrap_in_dictobs(obs)\n",
      "Cell \u001b[0;32mIn[2], line 172\u001b[0m, in \u001b[0;36mTrajFromFile.get_demo\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    170\u001b[0m depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth_data\u001b[39m\u001b[38;5;124m'\u001b[39m][idx]\n\u001b[1;32m    171\u001b[0m act\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkris_dynamics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124modom_data\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124modom_data_wheel\u001b[39m\u001b[38;5;124m'\u001b[39m][idx]\n\u001b[0;32m--> 172\u001b[0m rgb\u001b[38;5;241m=\u001b[39m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m depth\u001b[38;5;241m=\u001b[39mpreprocess(depth)\n\u001b[1;32m    174\u001b[0m (rgb, depth) \u001b[38;5;241m=\u001b[39m (rgb\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEVICE), depth\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEVICE))\n",
      "File \u001b[0;32m~/foxy_ws/src/gail_navigation/GailNavigationNetwork/GailNavigationNetwork/utilities.py:66\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     58\u001b[0m     rgb_transform \u001b[38;5;241m=\u001b[39m  v2\u001b[38;5;241m.\u001b[39mCompose([                      \n\u001b[1;32m     59\u001b[0m                     v2\u001b[38;5;241m.\u001b[39mToDtype(torch\u001b[38;5;241m.\u001b[39mfloat32, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     60\u001b[0m                     v2\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m]),\n\u001b[1;32m     61\u001b[0m                 ])\n\u001b[1;32m     62\u001b[0m     image \u001b[38;5;241m=\u001b[39m rgb_transform(image)\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "file_path=\"/home/foxy_user/foxy_ws/src/gail_navigation/GailNavigationNetwork/data/traj2.hdf5\"\n",
    "trajectory=TrajFromFile(file_path)\n",
    "print(\"Traj object created with lenth\",trajectory.len)\n",
    "trajs=trajectory.generate_trajectories(env,trajectory.len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_venv",
   "language": "python",
   "name": "thesis_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
