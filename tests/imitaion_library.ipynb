{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2a8296-db9e-41d4-b30d-e8deae92340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foxy_user/venvs/thesis_venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This is a simple example demonstrating how to clone the behavior of an expert.\n",
    "\n",
    "Refer to the jupyter notebooks for more detailed examples of how to use the algorithms.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "\n",
    "from imitation.algorithms import bc\n",
    "from imitation.data import rollout\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from imitation.policies.serialize import load_policy\n",
    "from imitation.util.util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4af5198-06eb-4aeb-8692-4119ee1826e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "env = make_vec_env(\n",
    "    \"seals:seals/CartPole-v0\",\n",
    "    rng=rng,\n",
    "    post_wrappers=[lambda env, _: RolloutInfoWrapper(env)],  # for computing rollouts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9abd2f11-401c-4d56-9c4f-3ad22d21ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_expert():\n",
    "    # note: use `download_expert` instead to download a pretrained, competent expert\n",
    "    print(\"Training a expert.\")\n",
    "    expert = PPO(\n",
    "        policy=MlpPolicy,\n",
    "        env=env,\n",
    "        seed=0,\n",
    "        batch_size=64,\n",
    "        ent_coef=0.0,\n",
    "        learning_rate=0.0003,\n",
    "        n_epochs=10,\n",
    "        n_steps=64,\n",
    "    )\n",
    "    expert.learn(1_000)  # Note: change this to 100_000 to train a decent expert.\n",
    "    return expert\n",
    "\n",
    "\n",
    "def download_expert():\n",
    "    print(\"Downloading a pretrained expert.\")\n",
    "    expert = load_policy(\n",
    "        \"ppo-huggingface\",\n",
    "        organization=\"HumanCompatibleAI\",\n",
    "        env_name=\"seals-CartPole-v0\",\n",
    "        venv=env,\n",
    "    )\n",
    "    return expert\n",
    "\n",
    "\n",
    "def sample_expert_transitions():\n",
    "    # expert = train_expert()  # uncomment to train your own expert\n",
    "    expert = download_expert()\n",
    "\n",
    "    print(\"Sampling expert transitions.\")\n",
    "    rollouts = rollout.rollout(\n",
    "        expert,\n",
    "        env,\n",
    "        rollout.make_sample_until(min_timesteps=None, min_episodes=50),\n",
    "        rng=rng,\n",
    "    )\n",
    "    return rollout.flatten_trajectories(rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a017d2fa-4633-42cc-87c5-6f36e836ca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading a pretrained expert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ppo-seals-CartPole-v0.zip: 100%|██████████| 139k/139k [00:00<00:00, 3.64MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling expert transitions.\n"
     ]
    }
   ],
   "source": [
    "transitions = sample_expert_transitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70dbada9-d9e0-4b6a-88ca-33388fff1e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions(obs=array([[ 0.0043625 ,  0.04350724,  0.03158535, -0.04972615],\n",
      "       [ 0.00523264,  0.23816238,  0.03059083, -0.33227867]],\n",
      "      dtype=float32), acts=array([1, 0]), infos=array([{}, {}], dtype=object), next_obs=array([[ 0.00523264,  0.23816238,  0.03059083, -0.33227867],\n",
      "       [ 0.00999589,  0.04261867,  0.02394526, -0.03010804]],\n",
      "      dtype=float32), dones=array([False, False]))\n"
     ]
    }
   ],
   "source": [
    "print(transitions[0:2]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "676de101",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Trajectory' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m infos\u001b[38;5;241m=\u001b[39m [{} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(no_of_transitions\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m      8\u001b[0m custom_dataset \u001b[38;5;241m=\u001b[39m Trajectory(obs\u001b[38;5;241m=\u001b[39mobs, acts\u001b[38;5;241m=\u001b[39macts,infos\u001b[38;5;241m=\u001b[39minfos,terminal\u001b[38;5;241m=\u001b[39mdones)\n\u001b[0;32m---> 10\u001b[0m rollout2\u001b[38;5;241m=\u001b[39m \u001b[43mrollout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(rollout2[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/venvs/thesis_venv/lib/python3.9/site-packages/imitation/data/rollout.py:580\u001b[0m, in \u001b[0;36mflatten_trajectories\u001b[0;34m(trajectories)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_of_type\u001b[39m(key, desired_type):\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(traj, key), desired_type) \u001b[38;5;28;01mfor\u001b[39;00m traj \u001b[38;5;129;01min\u001b[39;00m trajectories\n\u001b[1;32m    578\u001b[0m     )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mall_of_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDictObs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m all_of_type(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m all_of_type(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macts\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# mypy struggles without Any annotation here.\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# The necessary constraints are enforced above.\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/thesis_venv/lib/python3.9/site-packages/imitation/data/rollout.py:576\u001b[0m, in \u001b[0;36mflatten_trajectories.<locals>.all_of_type\u001b[0;34m(key, desired_type)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_of_type\u001b[39m(key, desired_type):\n\u001b[0;32m--> 576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(traj, key), desired_type) \u001b[38;5;28;01mfor\u001b[39;00m traj \u001b[38;5;129;01min\u001b[39;00m trajectories\n\u001b[1;32m    578\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Trajectory' object is not iterable"
     ]
    }
   ],
   "source": [
    "from imitation.data.types import Trajectory\n",
    "no_of_transitions = 10\n",
    "obs=np.ones(shape=(no_of_transitions,3))*3\n",
    "acts=np.ones(shape=(no_of_transitions-1,1))*5\n",
    "next_obs=np.ones(shape=(no_of_transitions,3))*7\n",
    "dones=np.zeros(shape=(no_of_transitions,1))\n",
    "infos= [{} for i in range(no_of_transitions-1)]\n",
    "custom_dataset = Trajectory(obs=obs, acts=acts,infos=infos,terminal=dones)\n",
    "\n",
    "rollout2= rollout.flatten_trajectories(custom_dataset)\n",
    "print(rollout2[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ce8ae-3126-4414-8c7e-bf24d2b5cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_trainer = bc.BC(\n",
    "    observation_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    demonstrations=transitions,\n",
    "    rng=rng,\n",
    ")\n",
    "\n",
    "evaluation_env = make_vec_env(\n",
    "    \"seals:seals/CartPole-v0\",\n",
    "    rng=rng,\n",
    "    env_make_kwargs={\"render_mode\": \"human\"},  # for rendering\n",
    ")\n",
    "\n",
    "print(\"Evaluating the untrained policy.\")\n",
    "reward, _ = evaluate_policy(\n",
    "    bc_trainer.policy,  # type: ignore[arg-type]\n",
    "    evaluation_env,\n",
    "    n_eval_episodes=3,\n",
    "    render=True,  # comment out to speed up\n",
    ")\n",
    "print(f\"Reward before training: {reward}\")\n",
    "\n",
    "print(\"Training a policy using Behavior Cloning\")\n",
    "bc_trainer.train(n_epochs=1)\n",
    "\n",
    "print(\"Evaluating the trained policy.\")\n",
    "reward, _ = evaluate_policy(\n",
    "    bc_trainer.policy,  # type: ignore[arg-type]\n",
    "    evaluation_env,\n",
    "    n_eval_episodes=3,\n",
    "    render=True,  # comment out to speed up\n",
    ")\n",
    "print(f\"Reward after training: {reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_venv",
   "language": "python",
   "name": "thesis_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
